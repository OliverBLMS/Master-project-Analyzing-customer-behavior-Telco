---
title: 'R notebook: Analysing customer behavior in Telco'
author: "Oliver Belmans"
output:
  html_notebook: 
    toc: yes
  html_document: default
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

# Work plan

Weekly progress is documented in this table. Hard **deadline** is 17-04-2017.

| week | Topic covered |
|------|---------------|
| w1   | Exploration of CDR, pre-processing, making usage features |

Things to cover in next weeks:

* Document KDD framework
* network features
* Cluster analysis (quality neuros / cluster) + sequence mining
* Evaluate results,  interpretation
* Documentation + report


# Week 1: Exploration of CDR, pre-processing, making usage features

## Workdirectory and packages/libraries

Basic steps to set the workdirectory and load the necessary packages/libraries.

```{r}
# get / set workdirectory to read in the datafile
################################################################################################################
setwd(dir = "/Users/oliver.belmans/Data/R_workdirectory/Thesis")
getwd()

# load packages/libraries used in the analysis
################################################################################################################
pkg <- c("tidyverse", "statnet", "igraph", "data.table")
lapply(pkg, require, character.only = TRUE)
```

## Read in data (or make dummy dataset)

The test CDR dataset only contain 100 record, whereas each record represents an edge between two nodes. However, the test set only contains isolated relationships between two nodes. So, instead of working on this test dataset, I created a dummy set on my own. 

```{r}

# read sample dataset (for now make sample set)
################################################################################################################
# read test CDR dataset
# sample_cdr <- fread(input = "sample_cdr.txt", header = TRUE, sep = ",", stringsAsFactors = FALSE)

# Make Dummy set with igraph
net <- sample_smallworld(dim = 1, size = 2000, nei =  20, p = 0.6, loops = FALSE, multiple = TRUE)

# function to generate date time for the variable CALL_START_DT_TM
size_net <- ecount(net)
date_time_gerenator <- function(N, st="2010/01/01", et="2010/01/31") {
  st <- as.POSIXct(as.Date(st))
  et <- as.POSIXct(as.Date(et))
  dt <- as.numeric(difftime(et,st,unit="sec"))
  ev <- sort(runif(N, 0, dt))
  rt <- st + ev
  sample(rt)
}

# transform graph dataset to dataframe and add extra variables (call date time, call duration)
sample_cdr <- data.table(as_data_frame(x = net)) %>%
  mutate(
# use size_net for correct number of records to generate
  CALL_START_DT_TM = date_time_gerenator(size_net),
# generate random call duration 
  CALL_ACTUAL_DURATION = round(abs(rnorm(size_net, 100, 200)),0)
)
# print head
head(sample_cdr)
```

### Pre-process (not clear with test set)

> A few question to keep in mind for the pre-processing
> 
* todo: Filter outliers or non relevant items
* todo: filter irrelevant user for network features, outside network? 
  * Possible: for those metric keep the whole network, but only for clustering keep the Nodes that belong to the network
* Question: how to label new customers? Since those are of interest in the sequence mining


## Creating breakdown structure

Next step is solving the date format, since the usage features will need a breakdown structure based on days, houres, peak houres,..

```{r}
# Variable manipulations
################################################################################################################

## CALL_START_DT to date format
## Create extra date/time variables like week-, daynumber, houres
sample_cdr <-
  sample_cdr %>%
  mutate(
  # CALL_START_DT_TM = strptime(paste(sample_cdr$CALL_START_DT, sample_cdr$CALL_START_TM),"%d%b%Y %H:%M:%S")
  WEEK_NR = format(CALL_START_DT_TM, "%U"),
  DAY_NR = format(CALL_START_DT_TM, "%w"),
  DAY = format(CALL_START_DT_TM, "%a"),
  HOUR = as.integer(format(CALL_START_DT_TM, "%H")),
  PEAK_HOUR = ifelse(HOUR >= 8 & HOUR <= 18, "PEAK", "NON-PEAK"),
  WEEKDAYS = ifelse(DAY_NR %in% c(0,6), "WEEKEND", "WEEK")
  )

# print head
head(sample_cdr)
```

## Create the usage metrics based on the breakdown structure (day, peak_hour, weekday)

Main idea is to generate these features on the dataset, but in order to generate trajectories, I need slice and aggregate data. 
I will slice the data per week as the total timeframe of the dataset will be 4 months. So a records that is involved from start to end will contains +- 16 aggregated records.

I choose to do feature extraction for these features:

* nr_call = number of calls
* ave_call_time = average call time
* total_call_time = sum of all call times

#### Aggregated by week

```{r}
# Variable creation based on usage
# create usage KPI 
################################################################################################################
# Create stats sliced (group_by) over week_nr

# global per week
week_set <- 
  sample_cdr %>%
  group_by(WEEK_NR, from) %>%
  summarise(
    nr_call= n(),
    ave_call_time = mean(CALL_ACTUAL_DURATION),
    total_call_time = sum(CALL_ACTUAL_DURATION)
  ) %>%
  gather(variable, value, -c(from, WEEK_NR)) %>%
  spread(variable, value, fill = 0)

# print head
head(week_set)

```

#### Aggregated by day

```{r}

day_set <- 
  sample_cdr %>%
  group_by(WEEK_NR, from, DAY) %>%
  summarise(
    nr_call= n(),
    ave_call_time = mean(CALL_ACTUAL_DURATION),
    total_call_time = sum(CALL_ACTUAL_DURATION)
  ) %>%
  gather(variable, value, -c(from, WEEK_NR, DAY)) %>%
  unite(temp, variable, DAY) %>%
  spread(temp, value, fill = 0)

# print head
head(day_set)
```

#### Aggregated by peak vs non-peak houres

```{r}
peak_set <-
  sample_cdr %>%
  group_by(WEEK_NR, from, PEAK_HOUR) %>%
  summarise(
    nr_call= n(),
    ave_call_time = mean(CALL_ACTUAL_DURATION),
    total_call_time = sum(CALL_ACTUAL_DURATION)
  ) %>%
  gather(variable, value, -c(from, WEEK_NR, PEAK_HOUR)) %>%
  unite(temp, variable, PEAK_HOUR) %>%
  spread(temp, value, fill = 0)

# print head
head(peak_set)
```

#### Aggregated by week- vs weekend-days

```{r}
weekday_set <- 
  sample_cdr %>%
  group_by(WEEK_NR, from, WEEKDAYS) %>%
  summarise(
    nr_call= n(),
    ave_call_time = mean(CALL_ACTUAL_DURATION),
    total_call_time = sum(CALL_ACTUAL_DURATION)
  ) %>%
  gather(variable, value, -c(from, WEEK_NR, WEEKDAYS)) %>%
  unite(temp, variable, WEEKDAYS) %>%
  spread(temp, value, fill = 0)

# print head
head(weekday_set)
```

#### Final dataset with the usage features

Lastly, join all the dataset so it contains per customer per week a wide format with all the usage features

```{r}

# merge sets
# week set must be the first in orde to set the avaiable (week_nr,from) as merge keys
dataset_usage_kpi <- Reduce(left_join, x = list(week_set, day_set, peak_set, weekday_set))

# print head
head(dataset_usage_kpi)
```



